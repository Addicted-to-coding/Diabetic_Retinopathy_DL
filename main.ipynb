{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f9b-PI_wIfoL",
        "outputId": "3570f721-5fdc-43b0-a51d-41ae09524940"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FKJUgNNGIWPj",
        "outputId": "05f4f1d4-3a92-446b-fc9c-1a79bc89152c"
      },
      "source": [
        "%cd drive/MyDrive/Fall2021/M226/Project/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Fall2021/M226/Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yZCvi9r3IW4a",
        "outputId": "728e8024-9a3e-4656-84a5-1b7c348c8961"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datapipeline_skeleton.ipynb  models.ipynb  train.csv\n",
            "filename.pickle              test.csv      \u001b[0m\u001b[01;34mtrain_images\u001b[0m/\n",
            "model_resnet18.pt            \u001b[01;34mtest_images\u001b[0m/  \u001b[01;34mtrain_images_resized\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4uJH6-6QjTx"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pickle\n",
        "from torch.utils import data\n",
        "import torch\n",
        "import random"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-aZSV5qx7Ma"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA-l-l3gIOSV"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from os import path"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYa-0KPcOtCL"
      },
      "source": [
        "# Function to resize images to (320, 320)\n",
        "# **No need to run it now**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEyqz7ZwFcj6"
      },
      "source": [
        "def resize_and_save_images(loc, original_dir, saving_dir, height = 320, width = 320):\n",
        "  data = pd.read_csv(loc)\n",
        "  for i in tqdm(range(len(data))):\n",
        "    image_filename = f'{data.iloc[i].id_code.strip()}.png'\n",
        "    file_loc = original_dir + image_filename\n",
        "    saving_loc = saving_dir + image_filename\n",
        "    if not path.exists(saving_loc):\n",
        "      try:\n",
        "        img = cv2.imread(file_loc)\n",
        "        img = cv2.resize(img, (width, height))\n",
        "        cv2.imwrite(saving_loc, img)\n",
        "      except:\n",
        "        unsaved.append(f'{image_filename}')\n",
        "        # print(f'{image_filename}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92BuZccayFKG",
        "outputId": "ce5887c0-ae45-45d0-8741-020061b2e8dd"
      },
      "source": [
        "resize_and_save_images('train.csv', 'train_images/', 'train_images_resized/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3662/3662 [00:19<00:00, 188.53it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju9T416lIchs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JricJ1ScOxiu"
      },
      "source": [
        "# Data pipeline creation\n",
        "### Creating train, valid, test split along with the dataloader "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0XQAMUFJrVJ"
      },
      "source": [
        "def get_image_label(data, dir, indices):\n",
        "\n",
        "  # just looking at 32 examples for testing purposes\n",
        "  X = np.array([np.asarray(Image.open(f'{dir}{data.iloc[i].id_code}.png')) for i in indices[:32]])\n",
        "  y = np.array([int(data.iloc[i].diagnosis) for i in indices[:32]])\n",
        "\n",
        "  return X,y"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3ZlPNQ-RuZn"
      },
      "source": [
        "def get_dataset(path, dir, train_size = 0.8, valid_size = 0.1):\n",
        "\n",
        "  data = pd.read_csv(path)\n",
        "  arr = [i for i in range(len(data))]\n",
        "  random.shuffle(arr)\n",
        "  train_indices = arr[: int(train_size * len(data)) ]\n",
        "  train_X, train_y = get_image_label(data, dir, train_indices)\n",
        "  train_X = train_X / 255.0\n",
        "\n",
        "  valid_indices = arr[int(train_size * len(data)) : int((train_size + valid_size) * len(data))]\n",
        "  valid_X, valid_y = get_image_label(data, dir, valid_indices)\n",
        "  valid_X = valid_X / 255.0\n",
        "\n",
        "  test_indices = arr[int((train_size + valid_size) * len(data)) : ]\n",
        "  test_X, test_y = get_image_label(data, dir, test_indices)\n",
        "  test_X = test_X / 255.0\n",
        "\n",
        "  return train_X, train_y, valid_X, valid_y, test_X, test_y"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B8uTa1xPYNI"
      },
      "source": [
        "# Set path to train.csv and train_images_resized folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3RL6t14K-PZ"
      },
      "source": [
        "train_X, train_y, valid_X, valid_y, test_X, test_y = get_dataset(\"train.csv\", 'train_images_resized/')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aG6wLJyNLXXp",
        "outputId": "ec5381aa-15a5-4d2d-bbd5-8fb86d702c14"
      },
      "source": [
        "train_X.shape, train_y.shape, valid_X.shape, valid_y.shape, test_X.shape, test_y.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 320, 320, 3), (32,), (32, 320, 320, 3), (32,), (32, 320, 320, 3), (32,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbqinByJPrvk"
      },
      "source": [
        "class DataGenerator(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    super(DataGenerator, self).__init__()\n",
        "    self.X = np.transpose(X, (0, 3, 1, 2))\n",
        "    self.y = y\n",
        "    self.length = len(X)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    return self.X[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9Wrp4rMZ-lq"
      },
      "source": [
        "bsz = 32\n",
        "\n",
        "train_dataset = DataGenerator(train_X, train_y)\n",
        "train_loader = data.DataLoader(train_dataset, batch_size= bsz, shuffle = True)\n",
        "\n",
        "valid_dataset = DataGenerator(valid_X, valid_y)\n",
        "valid_loader = data.DataLoader(valid_dataset, batch_size = bsz, shuffle = True)\n",
        "\n",
        "test_dataset = DataGenerator(test_X, test_y)\n",
        "test_loader = data.DataLoader(test_dataset, batch_size = bsz, shuffle = False)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAHnbcGvQlJD"
      },
      "source": [
        "## Model Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HNFvbIYmiI1"
      },
      "source": [
        "class generate_model(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, base_model, hidden = 128, num_outs = 5):\n",
        "    super(generate_model, self).__init__()\n",
        "\n",
        "    # create a dummy input\n",
        "    dummy_input = torch.rand(1, 3, 320, 320)\n",
        "    out = base_model(dummy_input.to(device).float())\n",
        "    input_size = out.shape[1]\n",
        "\n",
        "    self.base_model = base_model\n",
        "    self.fc = torch.nn.Sequential(\n",
        "                            torch.nn.Linear(input_size, hidden), \n",
        "                            torch.nn.ReLU(),\n",
        "                            torch.nn.Linear(hidden, num_outs)\n",
        "                            )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.base_model(x)\n",
        "    pred = self.fc(x)\n",
        "    return pred"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSjdJSpfXaZR"
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCilCkplxGMx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d77c034b-7647-481c-c7d3-23b21aeff83d"
      },
      "source": [
        "basemodel = models.resnet18().to(device)\n",
        "model = generate_model(base_model = basemodel).to(device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUW3Ifi7xKtK"
      },
      "source": [
        "# To get an idea of number of trainable params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wstkWbZkxM-3"
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 320, 320))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTLHrOg8rlQJ"
      },
      "source": [
        "# Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lePBxUITTGIh"
      },
      "source": [
        "model_file = \"model_resnet18.pt\"\n",
        "\n",
        "lr = 1e-4\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=lr)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn81P2bDTy9R"
      },
      "source": [
        "def evaluate(model, objective, loader):\n",
        "\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  size = 0\n",
        "  for batch_idx, data_batch in enumerate(loader):\n",
        "\n",
        "    X, y = data_batch[0].to(device).float(), data_batch[1].to(device)\n",
        "    # X, y = map(lambda t: t.to(device).float(), (X, y))\n",
        "\n",
        "    prediction = model(X)\n",
        "    total_loss += objective(prediction, y) * X.shape[0]\n",
        "    size += X.shape[0]\n",
        "\n",
        "  total_loss = total_loss / size\n",
        "\n",
        "  return total_loss"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YdGf7uaPicL"
      },
      "source": [
        "def train(model, objective, optimizer, train_loader, valid_loader, epochs = 1, save_interval = 1, patience = 3):\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  val_loss = 1e7\n",
        "  pat = patience\n",
        "\n",
        "  for epoch in range(1, epochs + 1):\n",
        "    train_loss = 0\n",
        "    size = 0\n",
        "\n",
        "    for batch_idx, data_batch in enumerate(train_loader):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      train_X, train_y = data_batch[0].to(device).float(), data_batch[1].to(device)\n",
        "      # train_X, train_y = map(lambda t: t.to(device).float(), (train_X, train_y))\n",
        "\n",
        "      prediction = model(train_X)\n",
        "      loss = objective(prediction, train_y)\n",
        "      loss.backward()\n",
        "\n",
        "      train_loss += loss.item() * train_X.shape[0]\n",
        "      size += train_X.shape[0]\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "    avg_loss = train_loss / size\n",
        "      \n",
        "    rt_val_loss = evaluate(model, objective, valid_loader)\n",
        "    model.train()\n",
        "\n",
        "    print(f'Epoch {epoch}: Training Loss : {avg_loss} | Validation loss : {rt_val_loss}')\n",
        "\n",
        "    if rt_val_loss < val_loss:\n",
        "      val_loss = rt_val_loss\n",
        "      torch.save(model.state_dict(), model_file)\n",
        "      pat = patience\n",
        "    else:\n",
        "      pat = pat - 1\n",
        "      if pat == 0:\n",
        "        print('Training Complete --> Exiting')\n",
        "        break    "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VrRYu4cHlM0V",
        "outputId": "d4e3165d-63d2-4508-e504-98fc4db79137"
      },
      "source": [
        "train(model, criterion, optimizer, train_loader, valid_loader, epochs = 10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Training Loss : 1.6469745635986328 | Validation loss : 1.5910922288894653\n",
            "Epoch 2: Training Loss : 1.4696815013885498 | Validation loss : 1.574928641319275\n",
            "Epoch 3: Training Loss : 1.3427343368530273 | Validation loss : 1.5636005401611328\n",
            "Epoch 4: Training Loss : 1.2360069751739502 | Validation loss : 1.5594807863235474\n",
            "Epoch 5: Training Loss : 1.1266865730285645 | Validation loss : 1.5683856010437012\n",
            "Epoch 6: Training Loss : 1.0135369300842285 | Validation loss : 1.5949983596801758\n",
            "Epoch 7: Training Loss : 0.9001538753509521 | Validation loss : 1.643510341644287\n",
            "Training Complete --> Exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9Zn7WbFlTUt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}